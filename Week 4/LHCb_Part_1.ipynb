{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LHCb_Part_1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMbLqgit0ZfJ7PPJipYRQky"
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JafiSIrvEKW",
        "colab_type": "text"
      },
      "source": [
        "Welcome to Week 4!\n",
        "\n",
        "We will be focussing in Particle Physics Analysis and detecting matter/antimatter assymetries in the production of certain types of particles. ![LHCb detector](https://www1b.physik.rwth-aachen.de/~schael/LHCb_files/LHCB%20PREVIEW-white-bg.jpg)\n",
        "\n",
        "The data we are using comes from LHCb - one of the experiments at LHC. It is a highly specialised detector aimed at detecting decays involving the B-quark. Unlike the other major experiments, LHCb detects particles very close to the source and looks almost exclusively in the forward direction - this gives the detector many advantages compared to other experiments at LHC.\n",
        "\n",
        "In order to get started, we need to access the [ROOT framework](https://root.cern.ch/) and download some datafiles into this machine.\n",
        "\n",
        "Before we start - we have to use Python2 (not Python 3), so we should choose this as an option in \"Runtime\" -> \"Change Runtime Type\" at the top."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFclIR72w0mU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we are going to make a directory called APPS\n",
        "!mkdir -p APPS\n",
        "#Now we move to our directory called APPS and we download ROOT from the CERN server, this version is chosen because it runs on this machine - if you want to run this locally check the versions!\n",
        "!cd APPS && wget https://root.cern.ch/download/root_v6.13.08.Linux-ubuntu18-x86_64-gcc7.3.tar.gz \n",
        "#Now we extract our downloaded file:\n",
        "!cd APPS && tar -xf root_v6.13.08.Linux-ubuntu18-x86_64-gcc7.3.tar.gz\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COPyXIvbxqht",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now we can extract some files from ROOT and ensure that we can access the libraries. We use some python key words to get access to the right files:\n",
        "\n",
        "import sys\n",
        "\n",
        "sys.path.append(\"/content/APPS/root/lib\")\n",
        "\n",
        "import ctypes\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libCore.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libThread.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libImt.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libRIO.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libNet.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libTree.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMathCore.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMatrix.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libHist.so')\n",
        "\n",
        "#ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libGraf.so')\n",
        "\n",
        "#ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libGraf3d.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMultiProc.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libMinuit.so')\n",
        "\n",
        "ctypes.cdll.LoadLibrary('/content/APPS/root/lib/libFoam.so')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTVz7NQMyDCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we can check if we have everything working as we expect: \n",
        "#Import brings the ROOT framework into our python environment.\n",
        "import ROOT\n",
        "#We define a 1 dimensional histogram, with 100 bins which ranges from -4 to +4\n",
        "h = ROOT.TH1F(\"gauss\",\"Example histogram\",100,-4,4)\n",
        "#Fill the histogram with gaussian (random) distribution\n",
        "h.FillRandom(\"gaus\")\n",
        "#make a Canvas (i.e. a drawing)\n",
        "c = ROOT.TCanvas(\"myCanvasName\",\"The Canvas Title\",800,600)\n",
        "#Draw my histogram\n",
        "h.Draw()\n",
        "#Show me the canvas\n",
        "c.Draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXW1M6XB0tXP",
        "colab_type": "text"
      },
      "source": [
        "All being well - this should give no errors and we should have some kind of Gaussian distribution above.\n",
        "\n",
        "The next step is to get our data from CERN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owIltKHIAmfl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p DATA && cd DATA  && wget http://opendata.cern.ch/record/4900/files/B2HHH_MagnetUp.root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co476pbmBvBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Since we need to use ROOT, we must first import this into Python:\n",
        "import ROOT\n",
        "#Then we open the ROOT file using the TFile command.\n",
        "f = ROOT.TFile.Open(\"DATA/B2HHH_MagnetUp.root\", \"READONLY\")\n",
        "#From our file, we have to extract the DecayTree \n",
        "tree=f.Get(\"DecayTree\")\n",
        "#Now we can grab some variables as a test:\n",
        "ymomentum = ROOT.RooRealVar(\"H1_PY\",\"H1 Y Momentum\",0,10000,\"MeV/c\")\n",
        "xmomentum = ROOT.RooRealVar(\"H1_PX\",\"H1 X Momentum\",0,10000,\"MeV/c\")\n",
        "zmomentum = ROOT.RooRealVar(\"H1_PZ\",\"H1 Z Momentum\",0,10000,\"MeV/c\")\n",
        "# We then create a dataset for us to play with\n",
        "data = ROOT.RooDataSet(\"data\",\"data set\", tree, ROOT.RooArgSet(xmomentum,ymomentum,zmomentum), \"1==1\")\n",
        "# Now we create a canvas, plot our data onto the canvas and draw it:\n",
        "c = ROOT.TCanvas(\"c\",\"c\")\n",
        "frame = xmomentum.frame()\n",
        "data.plotOn(frame)\n",
        "frame.Draw()\n",
        "c.Draw()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e4n4iS3IJZi",
        "colab_type": "text"
      },
      "source": [
        "#Why are we here?\n",
        "\n",
        "This week is about finding out something about one of the fundemental questions in physics. Why do we have \"stuff\".\n",
        "\n",
        "According to many of our models, and according to many measurements in particle physics, matter and anti-matter appear to be produced in equal quantities.\n",
        "\n",
        "However, when one looks at the Universe in general, we have more matter than anti-matter left - so there need to be some processes where anti-matter and matter are not produced equally. You can find out more about the Matter/Anti-Matter Asymmetry [here](http://press.web.cern.ch/backgrounders/matterantimatter-asymmetry)\n",
        "\n",
        "One place we look for this asymetry is in [charge-partity (CP) violation](https://www.symmetrymagazine.org/article/october-2005/explain-it-in-60-seconds) in particle physics processes. This essentially says that the processes that happen in the anti-particle version of a decay do not **exactly** match to the processes that happen in the particle version of the decay.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "At LHCb, we produce both particle of the  B<sup>+</sup> meson and it's antiparticle the B<sup>-</sup> meson.\n",
        "\n",
        "We cannot detect these mesons directly. They decay into other things before we have a chance to measure them properly. So we collect data on the decay products, often called daughter particles. There are 524 [documented](http://pdg.lbl.gov/2014/listings/rpp2014-list-B-plus-minus.pdf) ways that the B<sup>+/-</sup> decays into various combinations. In order to simplify the process, we choose decay combinations that are convenient or have particular properties.\n",
        "\n",
        "In this analysis, we will take the process:-\n",
        "\n",
        "B<sup>+</sup>->K<sup>+</sup> + K<sup>+</sup>  + K<sup>-</sup>\n",
        "\n",
        "or\n",
        "\n",
        "B<sup>-</sup>->K<sup>-</sup> + K<sup>-</sup>  + K<sup>+</sup>\n",
        "\n",
        "\n",
        "To do so, we are given the following data for each event in our system:-\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/lhcb/opendata-project/80d64a3796e593fc8f9b257e85f32ae2e54f131f/Images/Variables.png)\n",
        "\n",
        "Here, H1 is the detected daughter particle (so a Kaon or a Pion), **not** the B-meson - the mother particle. We have to use some detective work to extract the information we need on the original physics process at play.\n",
        "\n",
        "\n",
        "Let's get started with working with this data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOhfj7kfP-ao",
        "colab_type": "text"
      },
      "source": [
        "For our analysis, the momentum of each of the daughter particles is split into the three cartesian components. We need to first combine this into a single measurement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4keyoyTPjsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We need to tell Python what the total momentum is defined as mathematically - do that in this code block:\n",
        "\n",
        "#Hint: I suggest we define a function which we might want to use later - something like:\n",
        "\n",
        "def p_tot_daughter(daughter)\n",
        "  p_tot=sqrt((daughter+\"_PX\")**2+ .... etc \n",
        "  return p_tot\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1lXLMCoR1Gi",
        "colab_type": "text"
      },
      "source": [
        "Now plot the total momentum for one (or more) of the daughter particles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kdbiNpPR1QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#use the histogram plotting tools, call your function to find the total momentum and then plot it!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj5qv5kqSMIF",
        "colab_type": "text"
      },
      "source": [
        "The next step is to use the total momentum of the Kaon and its invarient mass (found with a small amount of research) and your relativity knowledge to get an equation for the energy of the Kaon. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMkih_6SSG8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#let's make a function to find the energy of a Kaon, if you add in the total momentum found in the previous steps - you should be able to do so reasonably easily"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3sqwtNTUEJd",
        "colab_type": "text"
      },
      "source": [
        "We have now completed the initial steps and begun to work through what we need to with the data. This workflow is divided into 4 stages, just for easier viewing and comprehension."
      ]
    }
  ]
}